{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Tensorflow...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fileinput\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import coremltools as ct \n",
    "\n",
    "print(\"Initiating Tensorflow...\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroke types in order\n",
    "STROKE_TYPE = [\"Serve\",\n",
    "            \"Forehand\",\n",
    "            \"Backhand\",\n",
    "            \"NoStroke\"]\n",
    "\n",
    "# Stroke type indices\n",
    "SERVE       = 0\n",
    "FOREHAND    = 1\n",
    "BACKHAND    = 2\n",
    "NOSTROKE    = 3\n",
    "\n",
    "# Video Keypoint locations\n",
    "SERVE_OUTPUT_LOC    = f\"videos/{STROKE_TYPE[SERVE]}/output/\"\n",
    "FOREHAND_OUTPUT_LOC = f\"videos/{STROKE_TYPE[FOREHAND]}/output/\"\n",
    "BACKHAND_OUTPUT_LOC = f\"videos/{STROKE_TYPE[BACKHAND]}/output/\"\n",
    "NOSTROKE_OUTPUT_LOC = f\"videos/{STROKE_TYPE[NOSTROKE]}/output/\"\n",
    "\n",
    "# Directory to save graphed distances for each stroke based on keypoints\n",
    "PLT_FILE_PATH       = \"images/\"\n",
    "\n",
    "# Frames in a video\n",
    "FRAMES_PER_SAMPLE   = 58\n",
    "\n",
    "# Required Mediapipe pose keypoints\n",
    "# Reference: https://github.com/google/mediapipe/blob/master/docs/solutions/pose.md\n",
    "LEFT_SHOULDER   = 11\n",
    "RIGHT_SHOULDER  = 12\n",
    "LEFT_HAND       = 15\n",
    "RIGHT_HAND      = 16\n",
    "LEFT_HIP        = 23 \n",
    "RIGHT_HIP       = 24\n",
    "LEFT_ANKLE      = 27\n",
    "RIGHT_ANKLE     = 28\n",
    "\n",
    "DISTANCES_TYPE = [\"RH to C\", \n",
    "                \"LH to C\", \n",
    "                \"RH to RA\", \n",
    "                \"LH to LA\",\n",
    "                \"RH to LH\",\n",
    "                \"RH to LHIP\",\n",
    "                \"LH to RHIP\",\n",
    "                \"MHIP-X to RH-X\",\n",
    "                \"MHIP-X to LH-X\"]\n",
    "\n",
    "# Each keypoint is of the form [ID, X, Y]\n",
    "ID      = 0\n",
    "X_COORD = 1\n",
    "Y_COORD = 2\n",
    "\n",
    "# Model Parameters\n",
    "RANDOM_SEED         = 42\n",
    "TEST_PERCENT        = 0.2   # Percent for Testing\n",
    "\n",
    "# Outputs from LSTM\n",
    "# Also used for hidden count\n",
    "LSTM_OP_SPACE       = 100\n",
    "\n",
    "DROPOUT_FACTOR      = 0.2\n",
    "MODEL_EPOCH_COUNT   = 50\n",
    "MODEL_BATCH_SIZE    = 32\n",
    "SHOULD_GEN_GRAPH    = False  # Generate graphs for each frame?\n",
    "MODEL_NAME          = \"models/tf_simple_lstm_model\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each type has dimensions: video_num, frame_num, key_num\n",
    "# Read the text file\n",
    "def getRows(location):\n",
    "    # Get all files in the folder\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(location):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_list.append(file_path)\n",
    "    \n",
    "    videos = []\n",
    "    # Iterate over each file and read its lines\n",
    "    for file_path in file_list:     # Parse all the videos\n",
    "        print(f\"File: {file_path}\")\n",
    "        frames = []\n",
    "        for line in fileinput.input(file_path): # Parse all the frames\n",
    "            i = 0\n",
    "            row = line.split()\n",
    "            row = [int(value) for value in row]\n",
    "            keypoints = []\n",
    "            while i < len(row): # Parse all the keypoints\n",
    "                keypoint = []\n",
    "                keypoint.append(row[i])\n",
    "                # print(row[i])\n",
    "                keypoint.append(row[i+1])\n",
    "                keypoint.append(row[i+2])\n",
    "                # print(str(keypoint) + '\\n')\n",
    "                keypoints.append(keypoint) \n",
    "                i += 3\n",
    "        \n",
    "            frames.append(keypoints)\n",
    "        fileinput.close()\n",
    "        videos.append(frames)\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points p0 and p1 are in the form [0:pointNum 1:xCoord 2:yCoord]\n",
    "def distance(p0, p1):\n",
    "    return math.sqrt(\n",
    "        (p1[X_COORD] - p0[X_COORD]) ** 2 + \n",
    "        (p1[Y_COORD] - p0[Y_COORD]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a directory if it doesn't exist\n",
    "# os.listdir()\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory Created!: {directory}\")\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This where the model building happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    STROKE_COUNT = len(STROKE_TYPE)\n",
    "    DISTANCES_COUNT  = len(DISTANCES_TYPE)\n",
    "\n",
    "    # construct the argument parser and parse the arguments\n",
    "    # ap = argparse.ArgumentParser()\n",
    "    # ap.add_argument(\"-g\", \"--graphs\", type=int, default=0,\n",
    "    #     help=\"Set as 0 if you dont want to generate graphs for the videos\")\n",
    "    # ap.add_argument(\"-o\", \"--optimize\", type=int, default=0,\n",
    "    #     help=\"Set as 0 if you dont want to optimize the model for mobile devices\")\n",
    "    # args = vars(ap.parse_args())\n",
    "\n",
    "    # SHOULD_GEN_GRAPH = args[\"graphs\"]\n",
    "    # SHOULD_MOBILE_OPTIMIZE = args[\"optimize\"]\n",
    "\n",
    "\n",
    "    print(\"Reading Keypoint files...\")\n",
    "\n",
    "    # Input keypoints for all videos (30 serves, 30 forehands, 30 backhands and 60 no stroke play) with 30 FPS Recordings\n",
    "    serves      = getRows(SERVE_OUTPUT_LOC)\n",
    "    forehands   = getRows(FOREHAND_OUTPUT_LOC)\n",
    "    backhands   = getRows(BACKHAND_OUTPUT_LOC)\n",
    "    nostrokes   = getRows(NOSTROKE_OUTPUT_LOC)\n",
    "\n",
    "    dataset = []\n",
    "    dataset.append(serves)\n",
    "    dataset.append(forehands)\n",
    "    dataset.append(backhands)\n",
    "    dataset.append(nostrokes)\n",
    "\n",
    "    # Color the distances\n",
    "    cmap = plt.get_cmap(\"rainbow\", DISTANCES_COUNT)  \n",
    "    # VIOLET        - RH to C\n",
    "    # BLUE          - LH to C\n",
    "    # LIGHT BLUE    - RH to RA\n",
    "    # CYAN          - LH to LA\n",
    "    # LIGHT GREEN   - RH to LH\n",
    "    # GREEN         - RH to LHIP\n",
    "    # LIGHT ORANGE  - LH to RHIP\n",
    "    # ORANGE        - MHIP-X to RH-X\n",
    "    # RED           - MHIP-X to LH-X\n",
    "\n",
    "    input_set = []\n",
    "    label_per_video = []\n",
    "    print(\"Calculating Distances...\\n\")\n",
    "    # For each set of keypoints in a video in all videos\n",
    "    for i in range(len(dataset)):\n",
    "        j = 0\n",
    "        for video in dataset[i]:\n",
    "            sequence = []\n",
    "            k = 0\n",
    "            for frame in video:\n",
    "                distances = []\n",
    "                # Calculate the 9 distances as follows:\n",
    "                chest_point = [-1, \n",
    "                            (frame[LEFT_SHOULDER][X_COORD]+\n",
    "                            frame[RIGHT_SHOULDER][X_COORD])/2,  \n",
    "                            (frame[LEFT_SHOULDER][Y_COORD]+\n",
    "                            frame[RIGHT_SHOULDER][Y_COORD])/2]\n",
    "                hip_center = [-1, \n",
    "                            (frame[LEFT_HIP][X_COORD]+\n",
    "                            frame[RIGHT_HIP][X_COORD])/2,  \n",
    "                            (frame[LEFT_HIP][Y_COORD]+\n",
    "                            frame[RIGHT_HIP][Y_COORD])/2]\n",
    "                # torso length is the distance between shoulder mid point and hip mid\n",
    "                torso_length = distance(chest_point, hip_center)\n",
    "                if torso_length == 0:\n",
    "                    print(f\"\\n\\nTorso Length 0 for {STROKE_TYPE[i]}_video_{j+1} Frame: {k+1}?\\nChest Point: {chest_point}, Hip Center: {hip_center}\\nDefaulting Torso Length to 1\")\n",
    "                    print(f\"Left Shoulder: {frame[LEFT_SHOULDER]}\")\n",
    "                    print(f\"Right Shoulder: {frame[RIGHT_SHOULDER]}\")\n",
    "                    print(f\"Left Hip: {frame[LEFT_HIP]}\")\n",
    "                    print(f\"Right Hip: {frame[RIGHT_HIP]}\")\n",
    "                    torso_length = 1\n",
    "                # Normalize all the distances based on torso length and append them to the distance array\n",
    "                # Dominant hand to chest \n",
    "                distances.append(distance(\n",
    "                                    frame[RIGHT_HAND], chest_point)/torso_length)\n",
    "                # Non-dominant hand to chest\n",
    "                distances.append(distance(\n",
    "                                    frame[LEFT_HAND], chest_point)/torso_length)\n",
    "                # Dominant hand to dominant side foot\n",
    "                distances.append(distance(\n",
    "                                    frame[RIGHT_HAND], frame[RIGHT_ANKLE])/torso_length)\n",
    "                # Non-dominant hand to non-dominant hand side foot\n",
    "                distances.append(distance(frame[LEFT_HAND], frame[LEFT_ANKLE])/torso_length)\n",
    "                # Hand to hand \n",
    "                distances.append(distance(frame[LEFT_HAND], frame[RIGHT_HAND])/torso_length)\n",
    "                # Dominant hand to nondominant side hip \n",
    "                distances.append(distance(frame[RIGHT_HAND], frame[LEFT_HIP])/torso_length)\n",
    "                # Non-Dominant hand to dominant side hip\n",
    "                distances.append(distance(frame[LEFT_HAND], frame[RIGHT_HIP])/torso_length)\n",
    "                # Body (Hip Center) to dominant hand x-axis distance\n",
    "                distances.append(abs(\n",
    "                                hip_center[X_COORD]-frame[RIGHT_HAND][X_COORD])/torso_length)\n",
    "                # Body (Hip Center) to non-dominant hand x-axis distance \n",
    "                distances.append(abs(\n",
    "                                hip_center[X_COORD]-frame[LEFT_HAND][X_COORD])/torso_length)\n",
    "                # Store in a data set array\n",
    "                sequence.append(distances)\n",
    "                k+=1\n",
    "            # print(f\"Generate Graphs: {SHOULD_GEN_GRAPH}\")\n",
    "            if SHOULD_GEN_GRAPH != 0:  \n",
    "                fig, ax = plt.subplots()\n",
    "                arr = np.array(sequence)\n",
    "                # Iterate over each distance column and plot with a different color\n",
    "                for l in range(DISTANCES_COUNT):\n",
    "                    ax.plot(arr[:,l], color=cmap(l), label=f\"{DISTANCES_TYPE[l]}\")    \n",
    "\n",
    "                # Set the title and labels\n",
    "                ax.set_title(f\"Distances for {STROKE_TYPE[i]}, Video {j+1}\")\n",
    "                ax.set_xlabel(\"Frames\")\n",
    "                ax.set_ylabel(\"Distance\")\n",
    "\n",
    "                # Add a legend outside the graph\n",
    "                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                # Create images directory\n",
    "                create_dir(PLT_FILE_PATH)\n",
    "                # Save graph path\n",
    "                filename = f\"{PLT_FILE_PATH}{STROKE_TYPE[i]}_video_{j+1}_distances.png\"\n",
    "                print(f\"Saved graph: {filename}\")\n",
    "                plt.savefig(filename, bbox_inches='tight')\n",
    "                # Close the figure to free up resources\n",
    "                plt.close(fig)\n",
    "            \n",
    "            input_set.append(sequence)\n",
    "            j+=1\n",
    "            # Label the video respectively as (0: Serve, 1: Forehand, 2: Backhand, 3: No Stroke) \n",
    "            label_per_video.append(i)\n",
    "\n",
    "    SAMPLE_COUNT = len(input_set) # Store total video count\n",
    "    # print(\"Inputs:\\n\", SAMPLE_COUNT)\n",
    "    # print(\"\\n\\nLabels:\\n\",label_per_video)\n",
    "\n",
    "    # Reshape the data matrix: Assuming you have a data matrix called data with shape (SAMPLE_COUNT, FRAMES_PER_SAMPLE, DISTANCES_COUNT), \n",
    "    # where the first dimension represents the number of videos, the second dimension represents the \n",
    "    # number of frames per video, and the third dimension represents the number of distances per frame. \n",
    "    # You can reshape this data matrix to have the shape (total_samples, timesteps, features).\n",
    "    reshaped_data = np.array(input_set).reshape((-1, FRAMES_PER_SAMPLE, DISTANCES_COUNT))\n",
    "    print(f\"Reshaped Data: {reshaped_data.shape}\")\n",
    "\n",
    "    # Assuming 'labels' is a list or array containing the action labels for each video\n",
    "    one_hot_labels = to_categorical(label_per_video)\n",
    "    print(f\"\\nOne hot Labels:\\n{one_hot_labels}\")\n",
    "\n",
    "    print(\"Splitting Dataset...\")\n",
    "    # Divide the data set samples into 80:20 for train:test\n",
    "\n",
    "    # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(reshaped_data, one_hot_labels, test_size=TEST_PERCENT, random_state=RANDOM_SEED)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=TEST_PERCENT, random_state=RANDOM_SEED)\n",
    "    # print(f\"Len of X_train: {len(X_train)}\\nLen of X_test: {len(X_test)}\\nLen of Y_train: {len(Y_train)}\\nLen of Y_test: {len(Y_test)}\\nLen of X_val: {len(X_val)}\\nLen of Y_val: {len(Y_val)}\")\n",
    "\n",
    "    print(\"Creating Simple LSTM Model...\")\n",
    "    # Training Phase\n",
    "    # Create a TF Sequential Model\n",
    "    model = Sequential()\n",
    "    # Add an LSTM Layer with 100 output space and input shape as FRAMES_PER_SAMPLExDISTANCES_COUNT (ref: https://sci-hub.se/https://doi.org/10.1109/CITISIA50690.2020.9371776)\n",
    "    model.add(LSTM(LSTM_OP_SPACE, input_shape=(FRAMES_PER_SAMPLE, DISTANCES_COUNT)))  # Adjust the number of units as needed\n",
    "    # Add a Dropout Layer with 100 output space\n",
    "    model.add(Dropout(DROPOUT_FACTOR))\n",
    "    # Add a Dense Layer with 100 output space\n",
    "    model.add(Dense(LSTM_OP_SPACE))\n",
    "    # Add a Dense Layer with STROKE_COUNT output space\n",
    "    model.add(Dense(STROKE_COUNT, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Fit the model with the current dataset with the xvalues and the labelvalues\n",
    "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=MODEL_EPOCH_COUNT, batch_size=MODEL_BATCH_SIZE)\n",
    "    # print(f\"\\nTensorflow Model:\\n{model}\")\n",
    "    print(f\"\\nModel Summary:\\n{model.summary()}\")\n",
    "\n",
    "\n",
    "    # The code commented below has not been tested to Optimize the model for phones\n",
    "    \"\"\"\n",
    "    if SHOULD_MOBILE_OPTIMIZE != 0:\n",
    "        from tensorflow.lite.python.util import run_graph_optimizations\n",
    "        from tensorflow.lite.python.convert import convert\n",
    "\n",
    "        # Apply model quantization\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        # Apply model compression techniques\n",
    "        # e.g. prune or quantize the model further\n",
    "\n",
    "        # Save the optimized model\n",
    "        with open('optimized_model.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        # Load and run the optimized model on mobile devices\n",
    "        interpreter = tf.lite.Interpreter(model_path='optimized_model.tflite')\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        # Prepare input data for inference\n",
    "        input_data = data.astype(np.float32)\n",
    "\n",
    "        # Run inference on the input data\n",
    "        interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
    "\n",
    "        # Evaluate the model accuracy\n",
    "        predicted_labels = np.argmax(output_data, axis=1)\n",
    "        accuracy = np.mean(predicted_labels == labels)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Testing Phase\n",
    "    # Call Predict function on the test array and get the label\n",
    "    # Test all the videos for testing and calculate the factors \"Precision\", \"Recall\", \"F1 Score\"\n",
    "        # Check this article for formulae: https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n",
    "\n",
    "    # Perform inference on testing data\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    print(f\"\\ny_test:\\n{y_test}\")\n",
    "    # Convert predicted probabilities to class labels (if needed)\n",
    "    predicted_labels = np.argmax(Y_pred, axis=1)\n",
    "    print(f\"predicted_labels:\\n{predicted_labels}\")\n",
    "\n",
    "    report = classification_report(y_test, predicted_labels)\n",
    "    print(f\"\\nModel Report:\\n{report}\")\n",
    "\n",
    "    # Save the model as SavedModel Format\n",
    "    model.save(f\"{MODEL_NAME}.h5\")\n",
    "\n",
    "    # To Save the model as HDF5\n",
    "    # model.save('your_model.h5')\n",
    "\n",
    "    print(f\"Model saved as {MODEL_NAME}...\")\n",
    "\n",
    "    # Define the flexible input shape (min: 1 x 58 x 9, max: 2 x 58 x 9)\n",
    "    input_shape = ct.Shape(shape=(ct.RangeDim(1, 2), 58, 9))\n",
    "\n",
    "    # Convert the Keras model to a CoreML model\n",
    "    coreml_model = ct.convert(\n",
    "        model,\n",
    "        inputs=[ct.TensorType(shape=input_shape)]\n",
    "    )\n",
    "\n",
    "    # Save the CoreML model to a file\n",
    "    coreml_model.save('coremodel.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Keypoint files...\n",
      "File: videos/Forehand/output/SHOT_NO49.mp4.points\n",
      "File: videos/Forehand/output/0021.mp4.points\n",
      "File: videos/Forehand/output/0016.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO37.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO9.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO11.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO26.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO44.mp4.points\n",
      "File: videos/Forehand/output/0007.mp4.points\n",
      "File: videos/Forehand/output/0030.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO4.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO23.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO14.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO41.mp4.points\n",
      "File: videos/Forehand/output/0029.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO1.mp4.points\n",
      "File: videos/Forehand/output/0002.mp4.points\n",
      "File: videos/Forehand/output/0013.mp4.points\n",
      "File: videos/Forehand/output/0024.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO19.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO50.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO32.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO35.mp4.points\n",
      "File: videos/Forehand/output/0008.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO29.mp4.points\n",
      "File: videos/Forehand/output/0014.mp4.points\n",
      "File: videos/Forehand/output/0023.mp4.points\n",
      "File: videos/Forehand/output/0005.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO6.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO38.mp4.points\n",
      "File: videos/Forehand/output/0019.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO24.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO13.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO46.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO3.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO16.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO21.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO43.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO30.mp4.points\n",
      "File: videos/Forehand/output/0026.mp4.points\n",
      "File: videos/Forehand/output/0011.mp4.points\n",
      "File: videos/Forehand/output/0028.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO22.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO15.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO40.mp4.points\n",
      "File: videos/Forehand/output/0003.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO18.mp4.points\n",
      "File: videos/Forehand/output/0012.mp4.points\n",
      "File: videos/Forehand/output/0025.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO33.mp4.points\n",
      "File: videos/Forehand/output/0020.mp4.points\n",
      "File: videos/Forehand/output/0017.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO48.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO36.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO8.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO10.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO27.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO45.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO5.mp4.points\n",
      "File: videos/Forehand/output/0006.mp4.points\n",
      "File: videos/Forehand/output/0001.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO2.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO17.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO20.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO42.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO31.mp4.points\n",
      "File: videos/Forehand/output/0027.mp4.points\n",
      "File: videos/Forehand/output/0010.mp4.points\n",
      "File: videos/Forehand/output/0009.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO34.mp4.points\n",
      "File: videos/Forehand/output/0015.mp4.points\n",
      "File: videos/Forehand/output/0022.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO28.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO7.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO39.mp4.points\n",
      "File: videos/Forehand/output/0004.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO25.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO12.mp4.points\n",
      "File: videos/Forehand/output/SHOT_NO47.mp4.points\n",
      "File: videos/Forehand/output/0018.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO49.mp4.points\n",
      "File: videos/Backhand/output/0021.mp4.points\n",
      "File: videos/Backhand/output/0016.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO37.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO9.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO11.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO26.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO44.mp4.points\n",
      "File: videos/Backhand/output/0007.mp4.points\n",
      "File: videos/Backhand/output/0030.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO4.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO23.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO14.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO41.mp4.points\n",
      "File: videos/Backhand/output/0029.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO1.mp4.points\n",
      "File: videos/Backhand/output/0002.mp4.points\n",
      "File: videos/Backhand/output/0013.mp4.points\n",
      "File: videos/Backhand/output/0024.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO19.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO50.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO32.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO35.mp4.points\n",
      "File: videos/Backhand/output/0008.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO29.mp4.points\n",
      "File: videos/Backhand/output/0014.mp4.points\n",
      "File: videos/Backhand/output/0023.mp4.points\n",
      "File: videos/Backhand/output/0005.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO6.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO38.mp4.points\n",
      "File: videos/Backhand/output/0019.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO24.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO13.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO46.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO3.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO16.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO21.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO43.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO30.mp4.points\n",
      "File: videos/Backhand/output/0026.mp4.points\n",
      "File: videos/Backhand/output/0011.mp4.points\n",
      "File: videos/Backhand/output/0028.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO22.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO15.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO40.mp4.points\n",
      "File: videos/Backhand/output/0003.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO18.mp4.points\n",
      "File: videos/Backhand/output/0012.mp4.points\n",
      "File: videos/Backhand/output/0025.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO33.mp4.points\n",
      "File: videos/Backhand/output/0020.mp4.points\n",
      "File: videos/Backhand/output/0017.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO48.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO36.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO8.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO10.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO27.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO45.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO5.mp4.points\n",
      "File: videos/Backhand/output/0006.mp4.points\n",
      "File: videos/Backhand/output/0001.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO2.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO17.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO20.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO42.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO31.mp4.points\n",
      "File: videos/Backhand/output/0027.mp4.points\n",
      "File: videos/Backhand/output/0010.mp4.points\n",
      "File: videos/Backhand/output/0009.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO34.mp4.points\n",
      "File: videos/Backhand/output/0015.mp4.points\n",
      "File: videos/Backhand/output/0022.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO28.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO7.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO39.mp4.points\n",
      "File: videos/Backhand/output/0004.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO25.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO12.mp4.points\n",
      "File: videos/Backhand/output/SHOT_NO47.mp4.points\n",
      "File: videos/Backhand/output/0018.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO49.mp4.points\n",
      "File: videos/NoStroke/output/0021.mp4.points\n",
      "File: videos/NoStroke/output/0016.mp4.points\n",
      "File: videos/NoStroke/output/0043.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO37.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO9.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO11.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO26.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO44.mp4.points\n",
      "File: videos/NoStroke/output/0052.mp4.points\n",
      "File: videos/NoStroke/output/0007.mp4.points\n",
      "File: videos/NoStroke/output/0030.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO4.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO23.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO14.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO41.mp4.points\n",
      "File: videos/NoStroke/output/0029.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO1.mp4.points\n",
      "File: videos/NoStroke/output/0057.mp4.points\n",
      "File: videos/NoStroke/output/0060.mp4.points\n",
      "File: videos/NoStroke/output/0035.mp4.points\n",
      "File: videos/NoStroke/output/0002.mp4.points\n",
      "File: videos/NoStroke/output/0013.mp4.points\n",
      "File: videos/NoStroke/output/0024.mp4.points\n",
      "File: videos/NoStroke/output/0046.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO19.mp4.points\n",
      "File: videos/NoStroke/output/0038.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO50.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO32.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO35.mp4.points\n",
      "File: videos/NoStroke/output/0008.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO29.mp4.points\n",
      "File: videos/NoStroke/output/0014.mp4.points\n",
      "File: videos/NoStroke/output/0023.mp4.points\n",
      "File: videos/NoStroke/output/0041.mp4.points\n",
      "File: videos/NoStroke/output/0050.mp4.points\n",
      "File: videos/NoStroke/output/0032.mp4.points\n",
      "File: videos/NoStroke/output/0005.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO6.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO38.mp4.points\n",
      "File: videos/NoStroke/output/0019.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO24.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO13.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO46.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO3.mp4.points\n",
      "File: videos/NoStroke/output/0055.mp4.points\n",
      "File: videos/NoStroke/output/0037.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO16.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO21.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO43.mp4.points\n",
      "File: videos/NoStroke/output/0049.mp4.points\n",
      "File: videos/NoStroke/output/0058.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO30.mp4.points\n",
      "File: videos/NoStroke/output/0026.mp4.points\n",
      "File: videos/NoStroke/output/0011.mp4.points\n",
      "File: videos/NoStroke/output/0044.mp4.points\n",
      "File: videos/NoStroke/output/0028.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO22.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO15.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO40.mp4.points\n",
      "File: videos/NoStroke/output/0056.mp4.points\n",
      "File: videos/NoStroke/output/0034.mp4.points\n",
      "File: videos/NoStroke/output/0003.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO18.mp4.points\n",
      "File: videos/NoStroke/output/0012.mp4.points\n",
      "File: videos/NoStroke/output/0025.mp4.points\n",
      "File: videos/NoStroke/output/0047.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO33.mp4.points\n",
      "File: videos/NoStroke/output/0039.mp4.points\n",
      "File: videos/NoStroke/output/0020.mp4.points\n",
      "File: videos/NoStroke/output/0017.mp4.points\n",
      "File: videos/NoStroke/output/0042.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO48.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO36.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO8.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO10.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO27.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO45.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO5.mp4.points\n",
      "File: videos/NoStroke/output/0053.mp4.points\n",
      "File: videos/NoStroke/output/0006.mp4.points\n",
      "File: videos/NoStroke/output/0031.mp4.points\n",
      "File: videos/NoStroke/output/0054.mp4.points\n",
      "File: videos/NoStroke/output/0001.mp4.points\n",
      "File: videos/NoStroke/output/0036.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO2.mp4.points\n",
      "File: videos/NoStroke/output/0048.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO17.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO20.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO42.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO31.mp4.points\n",
      "File: videos/NoStroke/output/0059.mp4.points\n",
      "File: videos/NoStroke/output/0027.mp4.points\n",
      "File: videos/NoStroke/output/0010.mp4.points\n",
      "File: videos/NoStroke/output/0045.mp4.points\n",
      "File: videos/NoStroke/output/0009.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO34.mp4.points\n",
      "File: videos/NoStroke/output/0015.mp4.points\n",
      "File: videos/NoStroke/output/0022.mp4.points\n",
      "File: videos/NoStroke/output/0040.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO28.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO7.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO39.mp4.points\n",
      "File: videos/NoStroke/output/0051.mp4.points\n",
      "File: videos/NoStroke/output/0033.mp4.points\n",
      "File: videos/NoStroke/output/0004.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO25.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO12.mp4.points\n",
      "File: videos/NoStroke/output/SHOT_NO47.mp4.points\n",
      "File: videos/NoStroke/output/0018.mp4.points\n",
      "Calculating Distances...\n",
      "\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 1?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 2?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 3?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 4?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 5?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 6?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 7?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 8?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 9?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 10?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 11?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 12?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 13?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 14?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 15?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 16?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 17?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 18?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 19?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 20?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 21?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 22?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 23?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 24?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 25?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 26?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 27?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 28?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 29?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 30?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 31?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 32?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 33?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 34?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 35?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 36?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 37?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 38?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 39?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 40?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 41?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 42?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 43?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 44?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 45?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 46?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 47?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 48?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 49?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 50?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 51?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 52?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 53?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 54?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 55?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 56?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 57?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "\n",
      "\n",
      "Torso Length 0 for NoStroke_video_75 Frame: 58?\n",
      "Chest Point: [-1, 0.0, 0.0], Hip Center: [-1, 0.0, 0.0]\n",
      "Defaulting Torso Length to 1\n",
      "Left Shoulder: [11, 0, 0]\n",
      "Right Shoulder: [12, 0, 0]\n",
      "Left Hip: [23, 0, 0]\n",
      "Right Hip: [24, 0, 0]\n",
      "Reshaped Data: (270, 58, 9)\n",
      "\n",
      "One hot Labels:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "Splitting Dataset...\n",
      "Creating Simple LSTM Model...\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 160ms/step - loss: 1.2518 - accuracy: 0.3663 - val_loss: 1.0851 - val_accuracy: 0.4545\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.0498 - accuracy: 0.4244 - val_loss: 1.0278 - val_accuracy: 0.5455\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0379 - accuracy: 0.4884 - val_loss: 1.0302 - val_accuracy: 0.4545\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9630 - accuracy: 0.4826 - val_loss: 0.9553 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8482 - accuracy: 0.6047 - val_loss: 0.9095 - val_accuracy: 0.6136\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7007 - accuracy: 0.6628 - val_loss: 0.8421 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.7146 - val_accuracy: 0.7045\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5916 - accuracy: 0.7791 - val_loss: 0.5459 - val_accuracy: 0.8409\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4704 - accuracy: 0.8198 - val_loss: 0.6296 - val_accuracy: 0.7955\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4178 - accuracy: 0.8547 - val_loss: 0.5471 - val_accuracy: 0.7955\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3747 - accuracy: 0.8779 - val_loss: 0.5188 - val_accuracy: 0.8636\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3148 - accuracy: 0.9128 - val_loss: 0.3924 - val_accuracy: 0.8864\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3415 - accuracy: 0.8953 - val_loss: 0.5261 - val_accuracy: 0.7955\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3251 - accuracy: 0.9070 - val_loss: 0.3600 - val_accuracy: 0.9091\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2280 - accuracy: 0.9419 - val_loss: 0.4314 - val_accuracy: 0.8864\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1200 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9545\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1227 - accuracy: 0.9709 - val_loss: 0.2493 - val_accuracy: 0.9318\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0961 - accuracy: 0.9651 - val_loss: 0.3507 - val_accuracy: 0.8864\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1591 - accuracy: 0.9477 - val_loss: 0.2381 - val_accuracy: 0.9318\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1166 - accuracy: 0.9593 - val_loss: 0.2381 - val_accuracy: 0.9545\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0757 - accuracy: 0.9826 - val_loss: 0.1889 - val_accuracy: 0.9545\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0528 - accuracy: 0.9942 - val_loss: 0.3007 - val_accuracy: 0.8864\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 0.1573 - val_accuracy: 0.9318\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0285 - accuracy: 0.9942 - val_loss: 0.1257 - val_accuracy: 0.9545\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9884 - val_loss: 0.1472 - val_accuracy: 0.9773\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1700 - accuracy: 0.9651 - val_loss: 0.5549 - val_accuracy: 0.8864\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1926 - accuracy: 0.9244 - val_loss: 0.3697 - val_accuracy: 0.9091\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1241 - accuracy: 0.9593 - val_loss: 0.3908 - val_accuracy: 0.8636\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.9651 - val_loss: 0.3292 - val_accuracy: 0.9091\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0623 - accuracy: 0.9709 - val_loss: 0.3751 - val_accuracy: 0.9091\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9091\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0247 - accuracy: 0.9942 - val_loss: 0.1992 - val_accuracy: 0.9545\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.1684 - val_accuracy: 0.9773\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9773\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9773\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9545\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9545\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9545\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9545\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9545\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9545\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9545\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9545\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9545\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9545\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.8856e-04 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9545\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.7576e-04 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9545\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.9223e-04 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9545\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.1723e-04 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9545\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 100)               44000     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54504 (212.91 KB)\n",
      "Trainable params: 54504 (212.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Model Summary:\n",
      "None\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "\n",
      "y_test:\n",
      "[1 2 1 2 3 2 3 1 2 3 3 3 3 2 3 3 3 2 2 1 3 3 1 1 3 1 1 3 2 1 2 1 2 3 3 1 2\n",
      " 1 2 2 1 2 3 1 1 3 2 3 2 3 1 2 3 3]\n",
      "predicted_labels:\n",
      "[1 2 1 2 3 2 3 1 2 3 3 3 3 2 1 3 3 2 2 1 3 3 1 1 3 1 1 3 2 1 1 1 2 3 3 1 2\n",
      " 1 2 1 1 2 2 1 1 3 2 3 2 3 1 2 3 3]\n",
      "\n",
      "Model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      1.00      0.91        16\n",
      "           2       0.94      0.88      0.91        17\n",
      "           3       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.93      0.93      0.92        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n",
      "Model saved as models/tf_simple_lstm_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhanshu/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_target' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://apple.github.io/coremltools/docs-guides/source/target-conversion-formats.html\n",
      "Running TensorFlow Graph Passes: 100%|| 6/6 [00:01<00:00,  4.26 passes/s]\n",
      "Converting TF Frontend ==> MIL Ops:   0%|          | 0/51 [00:00<?, ? ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting TF Frontend ==> MIL Ops: 100%|| 14/14 [00:00<00:00, 110376.42 ops/s]\n",
      "Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting TF Frontend ==> MIL Ops: 100%|| 41/41 [00:00<00:00, 1898.32 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|| 14/14 [00:00<00:00, 5010.69 ops/s]\n",
      "Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting TF Frontend ==> MIL Ops: 100%|| 41/41 [00:00<00:00, 10829.80 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops:  82%| | 42/51 [00:00<00:00, 301.73 ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting TF Frontend ==> MIL Ops: 100%|| 51/51 [00:00<00:00, 352.97 ops/s]\n",
      "Running MIL frontend_tensorflow2 pipeline: 100%|| 7/7 [00:00<00:00, 599.11 passes/s]\n",
      "Running MIL default pipeline: 100%|| 78/78 [00:00<00:00, 771.32 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|| 12/12 [00:00<00:00, 2016.41 passes/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
